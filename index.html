<!DOCTYPE html>
<html>
<head>
	<title>Saving the Limping</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
</head>
<body>
	<div class="container">
		<div class="container">
			<div class="center">
				<h2 class="text-center">Saving the Limping: Fault-tolerant Quadruped Locomotion via Reinforcement Learning</h2>
				<br>
				<div class="row authors justify-content-center text-center lead">
					<div class="col">
						<p>Dikai Liu<sup>1, 2</sup></p>
					</div>
					<div class="col">
						<p>Tianwei Zhang<sup>2</sup></p>
					</div>
					<div class="col">
						<p>Jianxiong Yin<sup>1</sup></p>
					</div>
					<div class="col">
						<p>Simon See<sup>1, 2, 3</sup></p>
					</div>
				</div>
				<div class="row affiliations justify-content-center text-center text-secondary">
					<div class="col-md-auto">
						<p><sup>1</sup>NVIDIA AI Technology Centre (NVAITC)</p>
					</div>
					<div class="col-md-auto">
						<p><sup>2</sup>Nanyang Technological University</p>
					</div>
					<div class="col-md-auto">
						<p><sup>3</sup>Coventry University</p>
					</div>
				</div>
			</div>
		</div>
		<br>
		<div class="container" style="font-size: 20px;">
			<div class="row justify-content-center text-center">
				<p>
					<a href="https://arxiv.org/abs/2210.00474">Paper</a>
				</p>
			</div>
		</div>
		<br>
		<div class="container text-center">
			<iframe width="560" height="315" src="https://www.youtube.com/embed/2gq-2L-VVVE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
		</div>
		<br>
		<div class="container">
			<h3 class="text-center mb-4">Abstract</h3>
			<p>With the rising focus on quadrupeds, a generalized policy capable of handling different robot models and sensor inputs becomes highly beneficial. Although several methods have been proposed to address different morphologies, it remains a challenge for learning-based policies to manage various combinations of proprioceptive information. This paper presents Masked Sensory-Temporal Attention (MSTA), a novel transformer-based mechanism with masking for quadruped locomotion. It employs direct sensor-level attention to enhance the sensory-temporal understanding and handle different combinations of sensor data, serving as a foundation for incorporating unseen information. MSTA can effectively understand its states even with a large portion of missing information, and is flexible enough to be deployed on physical systems despite the long input sequence.</p>
		</div>
	</div>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js" integrity="sha384-w76AqPfDkMBDXo30jS1Sgez6pr3x5MlQ1ZAGC+nuZB+EYdgRZgiwxhTBTkF7CXvN" crossorigin="anonymous"></script>
</body>
</html>